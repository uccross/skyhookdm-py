#!/usr/bin/env python

import os
import sys
import time
import logging
import tracemalloc

import numpy
import pyarrow

# classes
from skyhookdm_singlecell import skyhook
from skyhookdm_singlecell.util import ArgparseBuilder
from skyhookdm_singlecell.parsers import GeneExpressionMatrixParser
from skyhookdm_singlecell.dataformats import (SkyhookDataWrapper, SkyhookFileWriter)


# Set-up logger
stdout_handler = logging.StreamHandler(sys.stdout)
stdout_handler.setFormatter(logging.Formatter(
    fmt='{levelname} <{name} | {asctime} ~> {message}',
    style='{'
))

analysis_logger = logging.getLogger('analysis')
analysis_logger.addHandler(logging.FileHandler('analysis.log'))
analysis_logger.setLevel(logging.DEBUG)

logger = logging.getLogger('toolbox.convert-file-format')
logger.setLevel(logging.DEBUG)
logger.addHandler(stdout_handler)

debug = False

# ------------------------------
# Parse command-line arguments first
parsed_args, parsed_extra_args = (
    ArgparseBuilder.with_description('Program for converting between specialized file formats')
                   .add_input_dir_arg(
                         required=True
                        ,help_str='Path to root directory of gene expression in MTX format'
                    )
                   .add_input_metadata_file_arg(
                         required=False
                        ,help_str='Path to file containing metadata'
                    )
                   .add_batch_args(
                         required=False
                        ,help_str='Number of records to batch together in output file'
                    )
                   .add_output_file_arg(
                         required=False
                        ,help_str='Path to file to write serialized data'
                    )
                   .add_output_file_format_arg(
                         required=True
                        ,help_str=(
                             'File format for output files. '
                             'Supports: "flatbuffer" | "parquet" | "arrow"'
                         )
                    )
                   .add_output_dir_arg(
                         required=False
                        ,help_str='Path to directory to write partitioned data in parquet format'
                    )
                   .add_data_format_arg(
                         required=False
                        ,help_str='Format of input data. Supports: "flatbuffer" | "arrow"'
                    )
                   .add_has_header_flag_arg(required=False)
                   .add_analysis_arg(required=False)
                   .add_flatbuffer_flag_arg(required=False)
                   .parse_args()
)


def start_analysis(flag_analysis):
    if not flag_analysis: return

    start_time = time.time()

    analysis_logger.info('Starting tracemalloc analysis.')
    analysis_logger.info(f'Start time: {start_time}')
    tracemalloc.start()

    return start_time


def snapshot_analysis(flag_analysis):
    if not flag_analysis: return

    snapshot_time = time.time()

    analysis_snapshot = tracemalloc.take_snapshot()
    analysis_logger.info(f'Snapshot time: {snapshot_time}')
    analysis_logger.info(analysis_snapshot.statistics('filename'))

    return snapshot_time


def stop_analysis(flag_analysis):
    if not flag_analysis: return

    stop_time = time.time()

    tracemalloc.stop()
    analysis_logger.info('Stopped tracemalloc analysis.')
    analysis_logger.info(f'Stop time: {stop_time}')

    return stop_time


def parse_input_file(input_dir, files_have_header):
    logger.info('>>> parsing gene expression')

    gene_expr, gene_ann, cell_ann = GeneExpressionMatrixParser.gene_expr_from_dir(
        input_dir, has_header=files_have_header
    )

    # debug is module variable
    if debug:
        logger.debug('--- subsampling data to 100 genes and 20 cells')
        gene_expr.subsample_by_counts(gene_count=100, cell_count=20)

    logger.info('--- normalizing gene expression')
    gene_expr.pipeline_add_cpm_normalization()

    logger.debug('--- gene expression shape: {}'.format(gene_expr.expression.shape))
    sample = gene_expr.expression[:3]

    try:
        logger.debug(sample[sample > 0])

    except Exception:
        logger.debug(f'Malformatted attempt to print non-zeros.\nsample: {sample}')

    logger.info('<<< gene expression parsed')

    return gene_expr, gene_ann, cell_ann


def write_partitions_to_filesystem(data_wrapper, output_dir, partition_size,
                                   use_fb_meta, file_format, data_format,
                                   file_ext='skyhook'):
    logger.info('>>> serializing cell expression')

    # make directories if necessary
    if not os.path.isdir(output_dir): os.makedirs(output_dir)

    # simple binary formats
    if file_format == 'arrow':
        logger.info('--- writing in arrow binary format')
        SkyhookFileWriter.write_partitions_to_arrow(data_wrapper, output_dir, partition_size)

    elif file_format == 'parquet':
        logger.info('--- writing in parquet binary format')
        SkyhookFileWriter.write_partitions_to_parquet(data_wrapper, output_dir, partition_size)

    # TODO: Eventually add row-based flatbuffer format that doesn't use fb_meta
    elif file_format == 'flatbuffer':

        # Place into a flatbuffer structure in specified data format
        if use_fb_meta and data_format == 'arrow':
            logger.info('--- serializing data in arrow format wrapped in fb_meta')

            SkyhookFileWriter.write_partitions_to_flatbuffer(
                data_wrapper, output_dir, partition_size
            )

    else:
        logger.error(f'Unknown file format: {file_format}')

    logger.info('<<< cell expression serialized')


def write_data_to_filesystem(data_wrapper, output_file):
    logger.info('>>> serializing gene expression')

    if os.path.isfile(output_file):
        err_msg = 'Serialized file already exists. Finishing...'
        logger.error(err_msg)
        sys.exit(err_msg)

    if output_file.endswith('arrow'):
        SkyhookFileWriter.write_gene_expr_arrow(data_wrapper, output_file)

    elif output_file.endswith('parquet'):
        SkyhookFileWriter.write_gene_expr_parquet(data_wrapper, output_file)

    logger.info('<<< gene expression serialized')


# ------------------------------
if __name__ == '__main__':
    logger.debug('Parsed command-line arguments:\n{}'.format(
        '\n'.join([
            f'{arg_name:20s}: {arg_val}'
            for arg_name, arg_val in vars(parsed_args).items()
        ])
    ))

    if parsed_args.data_format not in ('arrow',):
        error_msg = f'xxx Unsupported data format: {parsed_args.data_format}'
        logger.error(error_msg)
        sys.exit(error_msg)

    start_time = start_analysis(parsed_args.should_analyze)

    # ------------------------------
    # Parse input file

    gene_expr = None
    if os.path.isdir(parsed_args.input_dir):
        gene_expr, gene_ann, cell_ann = parse_input_file(
            parsed_args.input_dir,
            parsed_args.flag_has_header
        )

    if gene_expr is None:
        sys.exit('Could not parse gene expression')

    # initialize wrappers here
    table_name = os.path.basename(parsed_args.input_dir)

    skyhook_expr_wrapper = SkyhookDataWrapper(
        table_name, gene_expr,
        type_for_numpy=numpy.uint16,
        type_for_arrow=pyarrow.uint16(),
        type_for_skyhook=skyhook.DataTypes.SDT_UINT16
    )

    skyhook_gene_wrapper = SkyhookDataWrapper(
        table_name, gene_ann,
        type_for_numpy=numpy.str,
        type_for_arrow=pyarrow.string(),
        type_for_skyhook=skyhook.DataTypes.SDT_STRING
    )

    skyhook_cell_wrapper = SkyhookDataWrapper(
        table_name, cell_ann,
        type_for_numpy=numpy.str,
        type_for_arrow=pyarrow.string(),
        type_for_skyhook=skyhook.DataTypes.SDT_STRING
    )

    # Log analysis after parsing the input file
    parse_time = snapshot_analysis(parsed_args.should_analyze)

    # ------------------------------
    # Write data in partitions
    if parsed_args.output_dir is not None:
        write_partitions_to_filesystem(
            skyhook_expr_wrapper,
            parsed_args.output_dir,
            parsed_args.batch_size,
            parsed_args.flag_use_wrapper,
            parsed_args.output_file_format,
            parsed_args.data_format
        )

        write_partitions_to_filesystem(
            skyhook_gene_wrapper,
            parsed_args.output_dir,
            parsed_args.batch_size,
            parsed_args.flag_use_wrapper,
            parsed_args.output_file_format,
            parsed_args.data_format,
            'genes.skyhook'
        )

        write_partitions_to_filesystem(
            skyhook_cell_wrapper,
            parsed_args.output_dir,
            parsed_args.batch_size,
            parsed_args.flag_use_wrapper,
            parsed_args.output_file_format,
            parsed_args.data_format,
            'cells.skyhook'
        )

    # ------------------------------
    # Write data in a single file
    if parsed_args.output_file is not None:
        write_data_to_filesystem(skyhook_expr_wrapper, parsed_args.output_file)

        write_data_to_filesystem(
            skyhook_gene_wrapper,
            parsed_args.output_file,
            '{}.genes{}'.format(*os.path.splitext(parsed_args.output_file))
        )

        write_data_to_filesystem(
            skyhook_cell_wrapper,
            parsed_args.output_file,
            '{}.cells{}'.format(*os.path.splitext(parsed_args.output_file))
        )

    # Log analysis after writing output file(s)
    write_time = snapshot_analysis(parsed_args.should_analyze)
    stop_time  = stop_analysis(parsed_args.should_analyze)

    if parsed_args.should_analyze:
        elapsed_parse_time = parse_time - start_time
        elapsed_write_time = write_time - parse_time
        elapsed_total_time = stop_time  - start_time

        analysis_logger.info(f'Parse time (m): {elapsed_parse_time/60}')
        analysis_logger.info(f'Write time (m): {elapsed_write_time/60}')
        analysis_logger.info(f'Total time (m): {elapsed_total_time/60}')

        logger.info(f'Total time: {elapsed_total_time/60}')
